#!/usr/bin/env node
/**
 * Voice Pipeline Test Script
 *
 * Tests the full pipeline: text â†’ intent/tone â†’ dialogue using OpenAI
 *
 * Usage:
 *   node --env-file=.env.local scripts/test-voice-pipeline.mjs
 *   node --env-file=.env.local scripts/test-voice-pipeline.mjs "I need a room for tonight"
 */

// Import voice services directly (no .ts extension for tsx)
import { getIntentToneService } from '../src/lib/voice/intent-tone';
import { getDialogueService } from '../src/lib/voice/dialogue';

// Test input (from CLI or default)
const userInput = process.argv[2] || "I need a room for tonight with two beds";

console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
console.log('  Voice Pipeline Test (OpenAI Live Integration)');
console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

console.log('ğŸ“ User input:', userInput);
console.log('');

// Mock hotel context
const hotelContext = {
  name: 'Lance Grand Hotel',
  amenities: ['rooftop pool', 'fitness center', 'spa', 'restaurant', 'free wifi'],
  policies: {
    check_in_time: '3:00 PM',
    check_out_time: '11:00 AM',
  },
};

(async function main() {
  try {
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // Step 1: Intent & Tone Classification
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    console.log('ğŸ” Step 1: Classifying intent and tone...\n');

    const intentToneService = getIntentToneService();
    const classification = await intentToneService.classify(userInput, []);

    console.log('âœ… Classification complete!\n');
    console.log('   Intent:', classification.intent.type);
    console.log('   Confidence:', (classification.intent.confidence * 100).toFixed(1) + '%');
    console.log('   Entities:', JSON.stringify(classification.intent.entities, null, 2));
    console.log('');
    console.log('   Emotion:', classification.tone.emotion);
    console.log('   Sentiment:', classification.tone.sentiment);
    console.log('   Urgency:', (classification.tone.urgency_score * 100).toFixed(1) + '%');
    console.log('   Politeness:', (classification.tone.politeness_score * 100).toFixed(1) + '%');
    console.log('');
    console.log('   â±ï¸  Latency:', classification.intent.latency_ms + 'ms');
    console.log('   ğŸ¤– Model:', classification.intent.model_used);
    console.log('');

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // Step 2: Dialogue Generation
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    console.log('ğŸ’¬ Step 2: Generating dialogue response...\n');

    const dialogueService = getDialogueService();

    const dialogueRequest = {
      userMessage: userInput,
      intent: {
        ...classification.intent,
        id: 'test-intent-' + Date.now(),
        utterance_id: 'test-utterance-' + Date.now(),
        extracted_at: new Date(),
      },
      tone: {
        ...classification.tone,
        id: 'test-tone-' + Date.now(),
        utterance_id: 'test-utterance-' + Date.now(),
        detected_at: new Date(),
      },
      hotelContext,
      conversationHistory: [],
    };

    const dialogueResponse = await dialogueService.generate(dialogueRequest);

    console.log('âœ… Response generated!\n');
    console.log('   ğŸ“¢ Assistant:', dialogueResponse.text);
    console.log('');
    console.log('   â±ï¸  Latency:', dialogueResponse.latency_ms + 'ms');
    console.log('   ğŸ”¢ Tokens:', dialogueResponse.total_tokens);
    console.log('   ğŸ¤– Model:', dialogueResponse.model);
    console.log('');

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // Step 3: Streaming Test (Optional)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    console.log('ğŸŒŠ Step 3: Testing streaming dialogue...\n');
    console.log('   ğŸ“¢ Assistant (streaming): ');
    process.stdout.write('      ');

    const streamedResponse = await dialogueService.generateStreaming(
      dialogueRequest,
      (token) => process.stdout.write(token)
    );

    console.log('\n');
    console.log('   â±ï¸  First token latency:', streamedResponse.latency_ms + 'ms');
    console.log('');

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // Summary
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('  âœ… Pipeline Complete!');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

    console.log('ğŸ“Š Performance Summary:');
    console.log('   Intent/Tone: ' + classification.intent.latency_ms + 'ms');
    console.log('   Dialogue: ' + dialogueResponse.latency_ms + 'ms');
    console.log('   Streaming: ' + streamedResponse.latency_ms + 'ms (first token)');
    const totalLatency = classification.intent.latency_ms + dialogueResponse.latency_ms;
    console.log('   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
    console.log('   Total: ' + totalLatency + 'ms');
    console.log('');

    if (totalLatency < 300) {
      console.log('ğŸ¯ Excellent latency! Well under 300ms target.\n');
    } else if (totalLatency < 500) {
      console.log('âœ… Good latency! Under 500ms.\n');
    } else {
      console.log('âš ï¸  Higher latency than expected (target: <300ms)\n');
    }

    console.log('ğŸ’¡ Try other inputs:');
    console.log('   node --env-file=.env.local scripts/test-voice-pipeline.mjs "What amenities do you have?"');
    console.log('   node --env-file=.env.local scripts/test-voice-pipeline.mjs "I have a problem with my room"');
    console.log('   node --env-file=.env.local scripts/test-voice-pipeline.mjs "Book a deluxe room for 3 guests"');
    console.log('');

  } catch (error: any) {
    console.error('\nâŒ Error:', error.message);
    console.error('\nStack:', error.stack);
    process.exit(1);
  }
})();
